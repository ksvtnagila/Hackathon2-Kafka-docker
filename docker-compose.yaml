version: "3.8"
services:
  zookeeper-1:
    container_name: zookeeper-1
    image: aimvector/zookeeper:2.7.0
    build:
      context: ./zookeeper
    volumes:
    - ./config/zookeeper-1/zookeeper.properties:/kafka/config/zookeeper.properties
    - ./data/zookeeper-1/:/tmp/zookeeper/
    networks:
    - kafka
  kafka-1:
    container_name: kafka-1
    image: aimvector/kafka:2.7.0
    build: 
      context: .
    volumes:
    - ./config/kafka-1/server.properties:/kafka/config/server.properties
    - ./data/kafka-1/:/tmp/kafka-logs/
    networks:
    - kafka
  kafka-2:
    container_name: kafka-2
    image: aimvector/kafka:2.7.0
    build: 
      context: .
    volumes:
    - ./config/kafka-2/server.properties:/kafka/config/server.properties
    - ./data/kafka-2/:/tmp/kafka-logs/
    networks:
    - kafka
  kafka-3:
    container_name: kafka-3
    image: aimvector/kafka:2.7.0
    build: 
      context: .
    volumes:
    - ./config/kafka-3/server.properties:/kafka/config/server.properties
    - ./data/kafka-3/:/tmp/kafka-logs/
    networks:
    - kafka
  kafka-producer:
    container_name: kafka-producer
    image: aimvector/kafka:2.7.0
    build: 
      context: .
    working_dir: /kafka
    entrypoint: /bin/bash
    stdin_open: true
    tty: true
    networks:
    - kafka
  kafka-consumer:
    container_name: kafka-consumer
    image: aimvector/kafka:2.7.0
    build: 
      context: .
    working_dir: /kafka
    entrypoint: /bin/bash
    stdin_open: true
    tty: true
    networks:
    - kafka
  kafka-consumer-go:
    container_name: kafka-consumer-go
    image: aimvector/kafka-consumer-go:1.0.0
    build: 
      context: ./applications/consumer
    environment:
    - "KAFKA_PEERS=kafka-1:9092,kafka-2:9092,kafka-3:9092"
    - "KAFKA_TOPIC=PricePrediction"
    - "KAFKA_VERSION=2.7.0"
    - "KAFKA_GROUP=PricePrediction"
    networks:
    - kafka
  spark_master:
    image: gettyimages/spark:2.4.1-hadoop-3.0
    command: bin/spark-class org.apache.spark.deploy.master.Master -h master
    hostname: master
    environment:
      MASTER: spark://master:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: localhost 
    expose:
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7077
      - 6066
    ports:
      - "4040:4040"
      - "6066:6066"
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./conf/master:/conf
      - ./data:/tmp/data

# create first Spark worker
  spark_worker:
    image: gettyimages/spark:2.4.1-hadoop-3.0
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077
    hostname: worker
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
    links:
      - "spark_master:master"
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 8881
    ports:
      - "8081:8081"
    volumes:
      - ./conf/worker:/conf
      - ./data:/tmp/data
    depends_on:
      - "spark_master"

# create second Spark worker
  spark_worker2:
    image: gettyimages/spark:2.4.1-hadoop-3.0
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077
    hostname: worker2
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8882
      SPARK_WORKER_WEBUI_PORT: 8082
      SPARK_PUBLIC_DNS: localhost
    links:
      - "spark_master:master"
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 8882
    ports:
      - "8082:8082"
    volumes:
      - ./conf/worker:/conf
      - ./data:/tmp/data
    depends_on:
      - "spark_master"
networks: 
  kafka:
    name: kafka